{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Práctica 2 segunda parte\n",
    "## Perfilamiento de MaxFlowAeiu\n",
    "\n",
    "El objetivo consiste en reimplementar nuestro método numérico realizado en la práctica 1 con niveles de BLAS, cómputo en paralelo (CPU/GPU), con compilación a C (por ejemplo vía cython, rcpp) o julia guiándose del perfilamiento de memoria, uso de procesador o tiempo de ejecución de su paquete. \n",
    "Usando una máquina de AWS con las siguientes características:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "La máquina `m4.16xlarge` tiene las siguientes características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit\n",
      "Byte Order:                      Little Endian\n",
      "CPU(s):                          4\n",
      "On-line CPU(s) list:             0-3\n",
      "Thread(s) per core:              1\n",
      "Core(s) per socket:              4\n",
      "Socket(s):                       1\n",
      "Vendor ID:                       0x00\n",
      "Model:                           0\n",
      "Stepping:                        0x0\n",
      "BogoMIPS:                        48.00\n",
      "Vulnerability Itlb multihit:     Not affected\n",
      "Vulnerability L1tf:              Not affected\n",
      "Vulnerability Mds:               Not affected\n",
      "Vulnerability Meltdown:          Not affected\n",
      "Vulnerability Spec store bypass: Vulnerable\n",
      "Vulnerability Spectre v1:        Mitigation; __user pointer sanitization\n",
      "Vulnerability Spectre v2:        Not affected\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Not affected\n",
      "Flags:                           fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm jscvt fcma lrcpc dcpop sha3 asimddp sha512 asimdfhm dit uscat ilrcpc flagm sb paca pacg dcpodp flagm2 frint\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux cb8cadb26507 5.10.47-linuxkit #1 SMP PREEMPT Sat Jul 3 21:50:16 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "uname -ar #r for kernel, a for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: MaxFlowAeiu in /home/myuser/.local/lib/python3.8/site-packages (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install MaxFlowAeiu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MaxFlowAeiu.MaxFlowAeiu import MaxFlowAeiu\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "from pytest import approx\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "block:read1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum flow in this network is 1480.0\n"
     ]
    }
   ],
   "source": [
    "url_d = \"https://raw.githubusercontent.com/optimizacion-2-2022-gh-classroom/practica-2-primera-parte-urieluard/main/BD/d.csv\"\n",
    "d = pd.read_csv(url_d,header=None)\n",
    "arreglo = d.values.tolist()\n",
    "MF=MaxFlowAeiu(arreglo)\n",
    "print(\"The maximum flow in this network is {}\".format(MF.ford_fulkerson()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Perfilamiento: medición de tiempo en Python y IPython\n",
    "\n",
    "Lo más natural que podemos pensar en medir es el tiempo de ejecución de nuestros códigos. Python y IPython tienen herramientas para este propósito.\n",
    "\n",
    "**Módulo: time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum flow in this network is 1480.0\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "url_d = \"https://raw.githubusercontent.com/optimizacion-2-2022-gh-classroom/practica-2-primera-parte-urieluard/main/BD/d.csv\"\n",
    "d = pd.read_csv(url_d,header=None)\n",
    "arreglo = d.values.tolist()\n",
    "MF=MaxFlowAeiu(arreglo)\n",
    "print(\"The maximum flow in this network is {}\".format(MF.ford_fulkerson()))\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El cálculo del flujo máximo usando MaxFlowAeiu tomó 0.5531389713287354 segundos\n"
     ]
    }
   ],
   "source": [
    "secs = end_time-start_time\n",
    "print(\"El cálculo del flujo máximo usando MaxFlowAeiu tomó\",secs,\"segundos\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Probamos que el paquete resuelve correctamente el problema con la función maximum_flow del paquete scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el mismo ejercicio pero usando `Scipy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import maximum_flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder usar la función de flujo máximo de `scipy`, es necesario tener la matriz en formato _sparse_, una vez representada de esta manera, es sencillo encontrar el valor del fliujo máximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1480"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generamos el arreglo final de tipo \"numpy array\"\n",
    "arreglo = d.to_numpy()\n",
    "arreglo\n",
    "arreglo2=arreglo.astype(int)\n",
    "graph = csr_matrix(arreglo2)\n",
    "maximum_flow(graph, 0, 43).flow_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arreglo = d.values.tolist()\n",
    "MF=MaxFlowAeiu(arreglo)\n",
    "mfaeiu=MF.ford_fulkerson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "flow_val=maximum_flow(graph, 0, 43).flow_value\n",
    "print(flow_val == mfaeiu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Comando de magic: %time**\n",
    "\n",
    "Este comando nos regresa las mediciones siguientes:\n",
    "\n",
    "**CPU times** que contiene:\n",
    "\n",
    "* user: mide la cantidad de tiempo de los statements que la CPU gastó para funciones que no están relacionadas con el kernel del sistema.\n",
    "\n",
    "* sys: mide la cantidad de tiempo de los statements que la CPU gastó en funciones a nivel de kernel del sistema.\n",
    "\n",
    "* total: suma entre el user y sys para todos todos los cores.\n",
    "\n",
    "**Wall time:** mide el wall clock o elapsed time que se refiere al tiempo desde que inicia la ejecución de los statements hasta su finalización.\n",
    "\n",
    "**Out:** resultado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 µs, sys: 0 ns, total: 14 µs\n",
      "Wall time: 26.9 µs\n",
      "The maximum flow in this network is 1480.0\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "arreglo = d.values.tolist()\n",
    "MF=MaxFlowAeiu(arreglo)\n",
    "print(\"The maximum flow in this network is {}\".format(MF.ford_fulkerson()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Tardó 14 milisegundos para funciones que no están relacionadas con el kernel del sistema.\n",
    "* Tardó 0 milisegundos para funciones a nivel kernel del sistema.\n",
    "* Tentiendo un total de 14 milisegundos unidades de tiempo.\n",
    "* Tardó 26.9 milisegundos desde el inicio hasta el fin de la ejecución de la función."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Timeit**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Se ejecuta desde la línea de comandos, con el comando de magic %timeit o realizando import.\n",
    "\n",
    "A continuación se mide el tiempo de ejecución para la función del flujo máximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum flow in this network is 1480.0\n"
     ]
    }
   ],
   "source": [
    "start = timeit.timeit()\n",
    "\n",
    "arreglo = d.values.tolist()\n",
    "MF=MaxFlowAeiu(arreglo)\n",
    "print(\"The maximum flow in this network is {}\".format(MF.ford_fulkerson()))\n",
    "\n",
    "end = timeit.timeit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El cálculo del flujo máximo usando MaxFlowAeiu tomó -0.02085841701773461 segundos\n"
     ]
    }
   ],
   "source": [
    "secs = end-start\n",
    "print(\"El cálculo del flujo máximo usando MaxFlowAeiu tomó\",secs,\"segundos\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**cProfile**\n",
    "\n",
    "cProfile está en la standard-library de Python como built-in. Se utiliza con la implementación CPython de Python para medir el tiempo de ejecución de cada función en el programa. Se ejecuta desde la línea de comandos, con un comando de magic o realizando import.\n",
    "\n",
    "El output de cProfile muestra:\n",
    "\n",
    "* El tiempo total de ejecución, el cual incluye el tiempo del bloque de código que estamos midiendo y el overhead al usar cProfile. Por esta razón se tiene un mayor tiempo de ejecución que con las mediciones de tiempo anteriores.\n",
    "\n",
    "* La columna ncalls que como el nombre indica, muestra el número de veces que se llamó a cada función. En este caso las funciones lambda y math.exp son las que se llaman un mayor número de veces: $n=106$ veces.\n",
    "\n",
    "* La columna tottime muestra el tiempo que tardaron estas funciones en ejecutarse (sin llamar a otras funciones).\n",
    "\n",
    "* La columna percall es el cociente entre tottime y ncalls.\n",
    "\n",
    "* La columna cumtime contiene el tiempo gastado en la función y en las demás que llama. \n",
    "\n",
    "* La columna de percall es un cociente entre la columna cumtime y el conteo del número de veces que se llamaron a funciones primitivas o también nombradas built in functions.\n",
    "\n",
    "* La última columna indica información de la función y la línea en la que se encuentra dentro del código. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum flow in this network is 1480.0\n",
      "         525 function calls in 0.016 seconds\n",
      "\n",
      "   Ordered by: call count\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      158    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "      158    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "       65    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        8    0.000    0.000    0.000    0.000 compilerop.py:174(extra_flags)\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        6    0.010    0.002    0.010    0.002 MaxFlowAeiu.py:27(busq_anchura)\n",
      "        4    0.001    0.000    0.001    0.000 {built-in method builtins.compile}\n",
      "        4    0.000    0.000    0.014    0.003 {built-in method builtins.exec}\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:82(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:108(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:117(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:238(helper)\n",
      "        4    0.000    0.000    0.000    0.000 traitlets.py:535(get)\n",
      "        4    0.000    0.000    0.000    0.000 traitlets.py:566(__get__)\n",
      "        4    0.000    0.000    0.001    0.000 codeop.py:142(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 interactiveshell.py:1142(user_global_ns)\n",
      "        4    0.000    0.000    0.000    0.000 interactiveshell.py:3167(compare)\n",
      "        4    0.000    0.000    0.014    0.003 interactiveshell.py:3215(run_code)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:513(is_set)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1017(_wait_for_tstate_lock)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1071(is_alive)\n",
      "        3    0.000    0.000    0.000    0.000 socket.py:480(send)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:96(_event_pipe)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:206(schedule)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:418(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:437(_schedule_flush)\n",
      "        2    0.000    0.000    0.001    0.000 iostream.py:500(write)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        1    0.000    0.000    0.001    0.001 {built-in method builtins.print}\n",
      "        1    0.000    0.000    0.000    0.000 1945787370.py:5(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 MaxFlowAeiu.py:9(__init__)\n",
      "        1    0.001    0.001    0.011    0.011 MaxFlowAeiu.py:74(ford_fulkerson)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\n",
      "        1    0.000    0.000    0.001    0.001 frame.py:10792(values)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:5585(__setattr__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:5640(_protect_consolidate)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:5658(f)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:5654(_consolidate_inplace)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:222(get_values)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:217(is_single_block)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:618(consolidate)\n",
      "        1    0.001    0.001    0.001    0.001 managers.py:1541(as_array)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1665(is_consolidated)\n",
      "        1    0.000    0.000    0.002    0.002 1945787370.py:4(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 1945787370.py:8(<module>)\n",
      "        1    0.000    0.000    0.012    0.012 1945787370.py:6(<module>)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cprof = cProfile.Profile()\n",
    "cprof.enable()\n",
    "\n",
    "arreglo = d.values.tolist()\n",
    "MF=MaxFlowAeiu(arreglo)\n",
    "print(\"The maximum flow in this network is {}\".format(MF.ford_fulkerson()))\n",
    "\n",
    "cprof.disable()\n",
    "cprof.print_stats(sort='ncalls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Observamos que la función que fue llamada más veces fue `append` al igual que `pop` con un total de 158 veces cada una, aunque de las que hicimos nosotros la más llamada es la de búsqueda de anchura con 6 llamadas y la que menos fue llamada fue `ford_fulkerson` la cual se encarga de obtener el flujo máximo de la red.\n",
    "* El tiempo total que tardaron estas funciones en correr de forma independiente fueron 0.016 segundos para todas las funciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**line_profiler**\n",
    "\n",
    "Nos ayuda a perfilar el código línea por línea.\n",
    "\n",
    "Una buena idea es perfilar el código primero con cProfile para identificar aquellas funciones que gastan un mayor tiempo de ejecución y posteriormente perfilarlas con `line_profiler`.\n",
    "\n",
    "Se ejecuta desde la línea de comandos, con un comando de magic o realizando import.\n",
    "\n",
    "El output de `line_profiler` muestra:\n",
    "\n",
    "* Line #: el número de la línea.\n",
    "\n",
    "* Hits: el número de veces que la línea fue ejecutada.\n",
    "\n",
    "* Time el tiempo que tomó la ejecución de la línea. Las unidades en el que se mide el tiempo está en la primer línea: Timer unit.\n",
    "\n",
    "* Per Hit: el tiempo promedio que toma la ejecución de la línea una vez en timer's units.\n",
    "\n",
    "* % Time: el porcentaje de tiempo que toma la ejecución de la línea correspondiente al tiempo total de ejecución de la función.\n",
    "\n",
    "* Line contents: el código a perfilar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Probemos con la función MaxFlowAeiu**\n",
    "aquí no supe cómo usarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m line_prof \u001b[38;5;241m=\u001b[39m line_profiler\u001b[38;5;241m.\u001b[39mLineProfiler()\n\u001b[1;32m      2\u001b[0m arreglo \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(line_prof(MaxFlowAeiu\u001b[38;5;241m.\u001b[39mford_fulkerson(\u001b[38;5;28;43mself\u001b[39;49m))(arreglo))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "line_prof = line_profiler.LineProfiler()\n",
    "arreglo = d.values.tolist()\n",
    "print(line_prof(MaxFlowAeiu.ford_fulkerson())(arreglo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(line_prof.print_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Perfilamiento: medición de uso de memoria en Python\n",
    "\n",
    "Si bien las computadoras de hoy en día tienen una gran cantidad de RAM es importante que las aplicaciones no utilicen la totalidad pues en ese caso se tendrá una penalización en el performance de la aplicación al utilizar virtual memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**memory_profiler**\n",
    "\n",
    "Se ejecuta desde la línea de comandos, con un comando de magic o realizando import. Al instalar memory_profiler se incluyen dos comandos de magic: %memit y %mprun. %mprun es similar a `line_profiler` al analizar línea por línea el uso de memoria.\n",
    "\n",
    "En el caso de import regresa una lista de valores de uso de memoria en MiB medidas cada cierto interval (argumento de memory_usage). En lo siguiente se pide que se regrese el máximo uso de memoria de la lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "%memit devuelve el pico de memoria usada en una celda de un jupyter notebook y utiliza las mismas ideas para reportar las mediciones que %timeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 215.61 MiB, increment: 0.55 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 217.70 MiB, increment: 2.01 MiB\n"
     ]
    }
   ],
   "source": [
    "arreglo = d.values.tolist()\n",
    "MF=MaxFlowAeiu(arreglo)\n",
    "%memit -c MF.ford_fulkerson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "[1] [Capítulo 5.2 del Libro de Optimización](https://itam-ds.github.io/analisis-numerico-computo-cientifico/5.optimizacion_de_codigo/5.2/Herramientas_de_lenguajes_y_del_SO_para_perfilamiento_e_implementaciones_de_BLAS.html])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volume_access_mode": "rwm",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
